#!/usr/bin/env python3

# Copyright (C) 2015  Stefano Zacchiroli <zack@upsilon.cc>,
#                     Antoine R. Dumont <antoine.romain.dumont@gmail.com>
# See the AUTHORS file at the top-level directory of this distribution
# License: GNU General Public License version 3, or any later version
# See top-level LICENSE file for more information

import argparse
import configparser
import logging
import os

import pygit2
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from sgloader import loader, models
from sgloader.db_utils import session_scope
from sgloader.models import ObjectCache


# Default configuration file
DEFAULT_CONF_FILE = '~/.config/sgloader.ini'


# default configuration (can be overriden by the DEFAULT_CONF_FILE)
DEFAULT_CONF = {
    'dataset_dir': './dataset',
    'log_dir': './log',
    'db_url': 'postgres:///swhgitloader'
}


def db_connect(db_url):
    """Given the db_url, return the couple (engine, session).
    """
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)

    return (engine, Session)


def parse_args():
    """ Parse the configuration for the cli.
    """
    cli = argparse.ArgumentParser(
        description='Parse git repositories objects and load them into a DB.')
    cli.add_argument('--verbose', '-v', action='store_true', help='Be verbose')
    cli.add_argument('--repo-path', '-r',
                     dest='repo_path',
                     help='Provide the git repository\'s path.')

    subcli = cli.add_subparsers(dest='action')
    subcli.add_parser('initdb', help='Initialize DB data')
    subcli.add_parser('cleandb', help='Clean DB data')

    args = cli.parse_args()

    if not args.repo_path and args.action != 'cleandb':
        cli.error('No repository given')

    return args


def read_conf(args):
    """Read the user's configuration file.

    args contains the repo to parse.
    Transmit to the result.

    (No cli override.)
    """
    config = configparser.ConfigParser(defaults=DEFAULT_CONF)
    config.read(os.path.expanduser(DEFAULT_CONF_FILE))

    conf = config._sections['main']
    conf['repo_path'] = args.repo_path

    return conf


def parse_git_repo(db_session, repo_path, dataset_dir):
    """Parse git repository `repo_path` and flush files on disk in `dataset_dir`.
    """
    def _store_blobs_from_tree(tree_ref, repo):
        """Given a tree, walk the tree and store the blobs in dataset
 (if not present in dataset/cache).
        """

        if loader.in_cache_objects(db_session, tree_ref):
            logging.debug("Tree \'%s\' already visited, skip!" % tree_ref.hex)
            return

        # Add the tree in cache
        loader.add_object_in_cache(db_session, tree_ref,
                                   ObjectCache.types["Tree"])

        # Now walk the tree
        for tree_entry in tree_ref:
            object_entry_ref = repo[tree_entry.id]

            # FIXME: find pythonic way to do type dispatch call to function?
            if isinstance(object_entry_ref, pygit2.Tree):
                logging.debug("Tree \'%s\' -> walk!" % object_entry_ref.hex)
                _store_blobs_from_tree(object_entry_ref, repo)
            elif isinstance(object_entry_ref, pygit2.Blob):
                if not loader.in_cache_objects(db_session, object_entry_ref):
                    logging.debug("Blob \'%s\' -> store in dataset !" %
                                  object_entry_ref.hex)
                    # add the file to the dataset on the filesystem
                    filepath = loader.add_file_in_dataset(db_session,
                                                          dataset_dir,
                                                          object_entry_ref)
                    # add the file to the file cache, pointing to the file
                    # path on the filesystem
                    loader.add_file_in_cache(db_session, object_entry_ref,
                                             filepath)
            else:
                logging.debug("Tag \'%s\' -> skip!" % object_entry_ref.hex)
                break

    repo = loader.load_repo(repo_path)
    all_refs = repo.listall_references()

    # for each ref in the repo
    for ref_name in all_refs:
        logging.debug("Parse reference \'%s\' " % ref_name)
        ref = repo.lookup_reference(ref_name)
        head_commit = ref.peel()
        # for each commit referenced by the commit graph starting at that ref
        for commit in loader.commits_from(repo, head_commit):
            # if we have a git commit cache and the commit is in there:
            if loader.in_cache_objects(db_session, commit):
                break  # stop treating the current commit sub-graph
            else:
                loader.add_object_in_cache(db_session, commit,
                                           ObjectCache.types["Commit"])
                _store_blobs_from_tree(commit.tree, repo)


if __name__ == '__main__':
    args = parse_args()
    conf = read_conf(args)

    log_filename = os.path.join(conf['log_dir'], 'sgloader.log')
    logging.basicConfig(filename=log_filename,
                        level=logging.DEBUG if args.verbose else logging.INFO)

    db_engine, mk_session = db_connect(conf['db_url'])

    if args.action == 'cleandb':
        logging.info("Database cleanup!")
        models.SQLBase.metadata.drop_all(db_engine)
    else:
        if args.action == 'initdb':
            logging.info("Database initialization!")
            models.SQLBase.metadata.create_all(db_engine)

        with session_scope(mk_session) as db_session:
            repo_path = conf['repo_path']
            logging.info("Parsing git repository \'%s\'" % repo_path)
            parse_git_repo(db_session, repo_path, conf['dataset_dir'])
